{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wms29/.local/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     id        topic     label  \\\n",
      "0  2401  Borderlands  Positive   \n",
      "1  2401  Borderlands  Positive   \n",
      "2  2401  Borderlands  Positive   \n",
      "3  2401  Borderlands  Positive   \n",
      "4  2401  Borderlands  Positive   \n",
      "\n",
      "                                                text  \n",
      "0  im getting on borderlands and i will murder yo...  \n",
      "1  I am coming to the borders and I will kill you...  \n",
      "2  im getting on borderlands and i will kill you ...  \n",
      "3  im coming on borderlands and i will murder you...  \n",
      "4  im getting on borderlands 2 and i will murder ...  \n",
      "                                                     text     label\n",
      "0     im getting on borderlands and i will murder you all  Positive\n",
      "1      i am coming to the borders and i will kill you all  Positive\n",
      "2       im getting on borderlands and i will kill you all  Positive\n",
      "3      im coming on borderlands and i will murder you all  Positive\n",
      "4  im getting on borderlands and i will murder you me all  Positive\n",
      "                                                                                                                                                                                                                                       text       label\n",
      "0  i mentioned on facebook that i was struggling for motivation to go for a run the other day which has been translated by toms great auntie as hayley cant get out of bed and told to his grandma who now thinks im a lazy terrible person  Irrelevant\n",
      "1                                                                                                                                       bbc news amazon boss jeff bezos rejects claims company acted like a drug dealer bbccouknewsavbusine     Neutral\n",
      "2                                                                                                                                                    microsoft why do i pay for word when it functions so poorly on my samsungus chromebook    Negative\n",
      "3                                                                                                                                                                      csgo matchmaking is so full of closet hacking its a truly awful game    Negative\n",
      "4                                                                              now the president is slapping americans in the face that he really did commit an unlawful act after his acquittal from discover on google vanityfaircomnewst     Neutral\n"
     ]
    }
   ],
   "source": [
    "#Import the data\n",
    "twitter_training = pd.read_csv('twitter_training.csv')\n",
    "twitter_validation = pd.read_csv('twitter_validation.csv')\n",
    "#get only text and label cols\n",
    "twitter_training_clean = twitter_training[['text','label']]\n",
    "twitter_validation_clean = twitter_validation[['text','label']]\n",
    "\n",
    "print(twitter_training.head())\n",
    "#Remove all non alpha characters row by row\n",
    "#clear nans\n",
    "twitter_training_clean = twitter_training_clean.dropna()\n",
    "for index, row in twitter_training_clean.iterrows():\n",
    "    try:\n",
    "        twitter_training_clean.at[index, 'text'] = ''.join(e for e in row['text'] if e.isalpha() or e.isspace())\n",
    "        twitter_training_clean.at[index, 'text'] = row['text'].lower()\n",
    "        twitter_training_clean.at[index, 'text'] = row['text'].strip()\n",
    "        twitter_training_clean.at[index, 'text'] = row['text'].split()\n",
    "        twitter_training_clean.at[index, 'text'] = ' '.join(row['text'])\n",
    "    except:\n",
    "        print(\"Error at index: \", index)\n",
    "        print(row['text'])\n",
    "#remove all rows with label = Irrelevant\n",
    "\n",
    "\n",
    "\n",
    "twitter_validation_clean = twitter_validation_clean.dropna()\n",
    "for index, row in twitter_validation_clean.iterrows():\n",
    "    try:\n",
    "        twitter_validation_clean.at[index, 'text'] = ''.join(e for e in row['text'] if e.isalpha() or e.isspace())\n",
    "        twitter_validation_clean.at[index, 'text'] = row['text'].lower()\n",
    "        twitter_validation_clean.at[index, 'text'] = row['text'].strip()\n",
    "        twitter_validation_clean.at[index, 'text'] = row['text'].split()\n",
    "        twitter_validation_clean.at[index, 'text'] = ' '.join(row['text'])\n",
    "    except:\n",
    "        print(\"Error at index: \", index)\n",
    "        print(row['text'])\n",
    "        \n",
    "print(twitter_training_clean.head().to_string())\n",
    "print(twitter_validation_clean.head().to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "SEED = 1234\n",
    "\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73996\n"
     ]
    }
   ],
   "source": [
    "#Create iterators from the pd\n",
    "from torchtext.legacy import data\n",
    "\n",
    "TEXT = data.Field(tokenize = 'spacy', include_lengths = True, tokenizer_language = 'en_core_web_sm')\n",
    "LABEL = data.LabelField(dtype = torch.float)\n",
    "print(len(twitter_training_clean))\n",
    "# try:\n",
    "#     train_data, test_data = torch.utils.data.random_split(twitter_training_clean, [int(len(twitter_training_clean)*0.9) , int(len(twitter_training_clean)*0.1)])\n",
    "# except:\n",
    "#     train_data, test_data = torch.utils.data.random_split(twitter_training_clean, [int(len(twitter_training_clean)*0.9) +1, int(len(twitter_training_clean)*0.1)])\n",
    "val_data = twitter_validation_clean\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "fields = [('label', LABEL), ('text', TEXT)]\n",
    "examples = [data.Example.fromlist([row['label'], row['text']], fields) for _, row in twitter_training_clean.iterrows()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = data.Dataset(examples, fields)\n",
    "train_data, test_data = dataset.split(split_ratio=0.9, random_state=random.seed(SEED))\n",
    "dataset_val = data.Dataset([data.Example.fromlist([row['label'], row['text']], fields) for _, row in twitter_validation_clean.iterrows()], fields)\n",
    "val_data = dataset_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['unk', 'or', 'rainbowsixde', 'or', 'is', 'this', 'no', 'joke', 'image', 'link', 'imgurcomaoltnd', 'and']\n"
     ]
    }
   ],
   "source": [
    "print(train_data[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT.build_vocab(train_data, max_size=25000, vectors=\"glove.6B.100d\", unk_init=torch.Tensor.normal_)\n",
    "LABEL.build_vocab(train_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "def example_sort_key(example):\n",
    "    return len(example.text)\n",
    "\n",
    "train_iterator, test_iterator = data.BucketIterator.splits(\n",
    "    (train_data, test_data), \n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    sort_key=example_sort_key,\n",
    "    device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    ")\n",
    "val_iterator = data.BucketIterator(\n",
    "    val_data,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    sort_key=example_sort_key,\n",
    "    device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    ")\n",
    "test_iterator_two = data.BucketIterator(\n",
    "    test_data,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    sort_key=example_sort_key,\n",
    "    device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a simple LSTM model for sentiment analysis\n",
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_dim, embedding_dim, hidden_dim, output_dim):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(input_dim, embedding_dim)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "        \n",
    "    def forward(self, text):\n",
    "        #convert text to a tensor\n",
    "\n",
    "        embedded = self.embedding(text)\n",
    "        output, (hidden, _) = self.lstm(embedded)\n",
    "        hidden_1D = hidden[-1, :, :]\n",
    "        return self.fc(hidden_1D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DIM = len(TEXT.vocab)\n",
    "EMBEDDING_DIM = 100\n",
    "HIDDEN_DIM = 256\n",
    "OUTPUT_DIM = 4  # Binary classification: positive or negative sentiment\n",
    "\n",
    "model = LSTMModel(INPUT_DIM, EMBEDDING_DIM, HIDDEN_DIM, OUTPUT_DIM)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method Module.parameters of LSTMModel(\n",
      "  (embedding): Embedding(25002, 100)\n",
      "  (lstm): LSTM(100, 256)\n",
      "  (fc): Linear(in_features=256, out_features=4, bias=True)\n",
      ")>\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "print(model.parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check what percent it got right\n",
    "def accuracy(model, iterator):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch in iterator:\n",
    "            text_tensor = batch.text  # This will be a tuple\n",
    "            text_tensor = text_tensor[0]  # Accessing the text tensor for the first field\n",
    "            target_labels = batch.label.type(torch.long)\n",
    "\n",
    "            predictions = model(text_tensor).squeeze(1)\n",
    "            _, predicted = torch.max(predictions.data, 1)\n",
    "            total += target_labels.size(0)\n",
    "            correct += (predicted == target_labels).sum().item()\n",
    "    return (100 * correct / total)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Train Loss: 1.2932, Test Loss: 1.3299, Time: 244.68s\n",
      "Epoch: 2, Train Loss: 0.8676, Test Loss: 1.0556, Time: 240.20s\n",
      "Epoch: 3, Train Loss: 0.4846, Test Loss: 0.9081, Time: 282.75s\n",
      "Epoch: 4, Train Loss: 0.2546, Test Loss: 0.8075, Time: 271.05s\n",
      "Epoch: 5, Train Loss: 0.1672, Test Loss: 0.7625, Time: 271.14s\n",
      "Epoch: 6, Train Loss: 0.1404, Test Loss: 0.7070, Time: 261.68s\n",
      "Epoch: 7, Train Loss: 0.1041, Test Loss: 0.6817, Time: 268.25s\n",
      "Epoch: 8, Train Loss: 0.0956, Test Loss: 0.6839, Time: 278.10s\n",
      "Epoch: 9, Train Loss: 0.0837, Test Loss: 0.7036, Time: 258.42s\n",
      "Epoch: 10, Train Loss: 0.0825, Test Loss: 0.7200, Time: 272.63s\n",
      "Epoch: 11, Train Loss: 0.0816, Test Loss: 0.7194, Time: 280.42s\n",
      "Epoch: 12, Train Loss: 0.0763, Test Loss: 0.6866, Time: 277.38s\n",
      "Epoch: 13, Train Loss: 0.0727, Test Loss: 0.6935, Time: 265.77s\n",
      "Epoch: 14, Train Loss: 0.0672, Test Loss: 0.6757, Time: 267.90s\n",
      "Epoch: 15, Train Loss: 0.0640, Test Loss: 0.6726, Time: 271.32s\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "def train(model, iterator, optimizer, criterion):\n",
    "    model.train()\n",
    "    for batch in iterator:\n",
    "        text_tensor = batch.text  # This will be a tuple\n",
    "        text_tensor = text_tensor[0]  # Accessing the text tensor for the first field\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        predictions = model(text_tensor).squeeze(1)\n",
    "\n",
    "        target_labels = batch.label.type(torch.long)\n",
    "\n",
    "\n",
    "        loss = criterion(predictions, target_labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "\n",
    "\n",
    "# Evaluation function\n",
    "def evaluate(model, iterator, criterion):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in iterator:\n",
    "            text_tensor = batch.text  # This will be a tuple\n",
    "            text_tensor = text_tensor[0]  # Accessing the text tensor for the first field\n",
    "            target_labels = batch.label.type(torch.long)\n",
    "\n",
    "            predictions = model(text_tensor).squeeze(1)\n",
    "            loss = criterion(predictions, target_labels)\n",
    "            total_loss += loss.item()\n",
    "    return total_loss / len(iterator)\n",
    "\n",
    "# Train the model for multiple epochs\n",
    "N_EPOCHS = 15\n",
    "for epoch in range(N_EPOCHS):\n",
    "    #Time execution\n",
    "    timer = time.time()\n",
    "\n",
    "    \n",
    "    train(model, train_iterator, optimizer, criterion)\n",
    "    train_loss = evaluate(model, train_iterator, criterion)\n",
    "    test_loss = evaluate(model, test_iterator, criterion)\n",
    "    # test_accuracy = accuracy(model, test_iterator)\n",
    "    print(f'Epoch: {epoch+1}, Train Loss: {train_loss:.4f}, Test Loss: {test_loss:.4f}, Time: {time.time() - timer:.2f}s')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'val_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/wms29/MachineLearning/P3/pytorch.ipynb Cell 16\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/wms29/MachineLearning/P3/pytorch.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m#Test val_data\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu/home/wms29/MachineLearning/P3/pytorch.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mtype\u001b[39m(val_data))\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/wms29/MachineLearning/P3/pytorch.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mtype\u001b[39m(val_iterator))\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/wms29/MachineLearning/P3/pytorch.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m val_accuracy \u001b[39m=\u001b[39m accuracy(model, val_iterator)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'val_data' is not defined"
     ]
    }
   ],
   "source": [
    "#Test val_data\n",
    "print(type(val_data))\n",
    "print(type(val_iterator))\n",
    "val_accuracy = accuracy(model, val_iterator)\n",
    "test_accuracy = accuracy(model, test_iterator)\n",
    "test_two_accuracy = accuracy(model, test_iterator_two)\n",
    "train_accuracy = accuracy(model, train_iterator)\n",
    "print(f'Val Accuracy: {val_accuracy:.4f}')\n",
    "print(f'Test Accuracy: {test_accuracy:.4f}')\n",
    "print(f'Test Two Accuracy: {test_two_accuracy:.4f}')\n",
    "print(f\"Train Accuracy: {train_accuracy:.4f}\")\n",
    "print(len(val_data))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'TEXT' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/wms29/MachineLearning/P3/pytorch.ipynb Cell 17\u001b[0m line \u001b[0;36m1\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/wms29/MachineLearning/P3/pytorch.ipynb#X22sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m tensor\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/wms29/MachineLearning/P3/pytorch.ipynb#X22sdnNjb2RlLXJlbW90ZQ%3D%3D?line=8'>9</a>\u001b[0m temp_sentence  \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mI want to quit my job and I hate the government. I really hate this \u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m---> <a href='vscode-notebook-cell://wsl%2Bubuntu/home/wms29/MachineLearning/P3/pytorch.ipynb#X22sdnNjb2RlLXJlbW90ZQ%3D%3D?line=9'>10</a>\u001b[0m temp_tensor \u001b[39m=\u001b[39m convert_sentence_to_tensor(temp_sentence)\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/wms29/MachineLearning/P3/pytorch.ipynb#X22sdnNjb2RlLXJlbW90ZQ%3D%3D?line=10'>11</a>\u001b[0m pred \u001b[39m=\u001b[39m model(temp_tensor)\u001b[39m.\u001b[39munsqueeze(\u001b[39m1\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/wms29/MachineLearning/P3/pytorch.ipynb#X22sdnNjb2RlLXJlbW90ZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39mprint\u001b[39m(pred)\n",
      "\u001b[1;32m/home/wms29/MachineLearning/P3/pytorch.ipynb Cell 17\u001b[0m line \u001b[0;36m5\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/wms29/MachineLearning/P3/pytorch.ipynb#X22sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mconvert_sentence_to_tensor\u001b[39m(sentence):\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/wms29/MachineLearning/P3/pytorch.ipynb#X22sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m     tokenized \u001b[39m=\u001b[39m [tok \u001b[39mfor\u001b[39;00m tok \u001b[39min\u001b[39;00m sentence]\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu/home/wms29/MachineLearning/P3/pytorch.ipynb#X22sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m     indexed \u001b[39m=\u001b[39m [TEXT\u001b[39m.\u001b[39mvocab\u001b[39m.\u001b[39mstoi[t] \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m tokenized]\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/wms29/MachineLearning/P3/pytorch.ipynb#X22sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m     tensor \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mLongTensor(indexed)\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/wms29/MachineLearning/P3/pytorch.ipynb#X22sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m     tensor \u001b[39m=\u001b[39m tensor\u001b[39m.\u001b[39munsqueeze(\u001b[39m1\u001b[39m)\n",
      "\u001b[1;32m/home/wms29/MachineLearning/P3/pytorch.ipynb Cell 17\u001b[0m line \u001b[0;36m5\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/wms29/MachineLearning/P3/pytorch.ipynb#X22sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mconvert_sentence_to_tensor\u001b[39m(sentence):\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/wms29/MachineLearning/P3/pytorch.ipynb#X22sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m     tokenized \u001b[39m=\u001b[39m [tok \u001b[39mfor\u001b[39;00m tok \u001b[39min\u001b[39;00m sentence]\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu/home/wms29/MachineLearning/P3/pytorch.ipynb#X22sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m     indexed \u001b[39m=\u001b[39m [TEXT\u001b[39m.\u001b[39mvocab\u001b[39m.\u001b[39mstoi[t] \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m tokenized]\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/wms29/MachineLearning/P3/pytorch.ipynb#X22sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m     tensor \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mLongTensor(indexed)\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/wms29/MachineLearning/P3/pytorch.ipynb#X22sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m     tensor \u001b[39m=\u001b[39m tensor\u001b[39m.\u001b[39munsqueeze(\u001b[39m1\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'TEXT' is not defined"
     ]
    }
   ],
   "source": [
    "#Test the model on a signle sentence data point\n",
    "#function to convert a ssetence to a tensor\n",
    "def convert_sentence_to_tensor(sentence):\n",
    "    tokenized = [tok for tok in sentence]\n",
    "    indexed = [TEXT.vocab.stoi[t] for t in tokenized]\n",
    "    tensor = torch.LongTensor(indexed)\n",
    "    tensor = tensor.unsqueeze(1)\n",
    "    return tensor\n",
    "temp_sentence  = 'I want to quit my job and I hate the government. I really hate this '\n",
    "temp_tensor = convert_sentence_to_tensor(temp_sentence)\n",
    "pred = model(temp_tensor).unsqueeze(1)\n",
    "\n",
    "print(pred)\n",
    "print(torch.argmax(pred))\n",
    "#print the label\n",
    "print(LABEL.vocab.itos[torch.argmax(pred)])\n",
    "# print(LABEL.vocab.stoi['negative'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
